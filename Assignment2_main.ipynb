{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sKEV-sUostG"
      },
      "source": [
        "\n",
        "# COS30049 - Assignment 2\n",
        "### Session 26 Group 2\n",
        "### Swinburne Univeristy of Technology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.0 Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Verify the DataSet Can Be Read\n",
        "Checks to verify:\n",
        "- File exists\n",
        "- Columns pesent\n",
        "- No missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully!\n",
            "Columns: ['id', 'tweet', 'label']\n",
            "   id                                              tweet label\n",
            "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
            "1   2  States reported 1121 deaths a small rise from ...  real\n",
            "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
            "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
            "4   5  Populous states can generate large case counts...  real\n"
          ]
        }
      ],
      "source": [
        "file_path = \"Constraint_English_Train.xlsx\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    misinfo_data = pd.read_excel(file_path)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(\"Columns:\", misinfo_data.columns.tolist())\n",
        "    print(misinfo_data.head())\n",
        "else:\n",
        "    print(\"File not found:\", file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Test Retrieval of Data Matching \"CDC\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows containing 'CDC':\n",
            "        id                                              tweet label\n",
            "0        1  The CDC currently reports 99031 deaths. In gen...  real\n",
            "6        7  If you tested positive for #COVID19 and have n...  real\n",
            "27      28  Just Appendix B gathering all the state orders...  real\n",
            "33      34  CDC Recommends Mothers Stop Breastfeeding To B...  fake\n",
            "138    139  Youth sports organizations: As you resume acti...  real\n",
            "...    ...                                                ...   ...\n",
            "6338  6339  ???The CDC can detain anyone with a fever ??\" ...  fake\n",
            "6345  6346  1645 deaths were reported today bringing the t...  real\n",
            "6377  6378  Acc to @CDCgov &amp; @WHO there is currently n...  real\n",
            "6391  6392  The CDC ???adjusted the US Covid deaths from 1...  fake\n",
            "6405  6406  The cloth face coverings recommended to slow s...  real\n",
            "\n",
            "[281 rows x 3 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/w0/r8xr9pyn4w19x3x9z5x82hm00000gn/T/ipykernel_96455/49314103.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  matches = misinfo_data.applymap(lambda x: bool(pattern.search(str(x))))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file_path = \"Constraint_English_Train.xlsx\"\n",
        "misinfo_data = pd.read_excel(file_path)\n",
        "\n",
        "# Compile the regex pattern\n",
        "pattern = re.compile(r'CDC', re.IGNORECASE)  # ignore case if needed\n",
        "\n",
        "# Example: check in a specific column, e.g., 'text'\n",
        "if 'text' in misinfo_data.columns:\n",
        "    matches = misinfo_data['text'].apply(lambda x: bool(pattern.search(str(x))))\n",
        "    print(\"Rows containing 'CDC':\")\n",
        "    print(misinfo_data[matches])\n",
        "else:\n",
        "    # If you want to search all columns\n",
        "    matches = misinfo_data.applymap(lambda x: bool(pattern.search(str(x))))\n",
        "    print(\"Rows containing 'CDC':\")\n",
        "    print(misinfo_data[matches.any(axis=1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Combine data sets\n",
        "- Datasets have been cleaned in Google Refine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/ctip/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "/opt/anaconda3/envs/ctip/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "/opt/anaconda3/envs/ctip/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_excel(\"Constraint_English_Train_GR.xlsx\")\n",
        "val_df = pd.read_excel(\"Constraint_English_Val_GR.xlsx\")\n",
        "test_df = pd.read_excel(\"Constraint_English_Test_GR.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.0 Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are using GR-tagged xlsx files instead of the original provided datasets. GR = Google Refine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Emoji and Symbols Refining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Emoji and Symbols Detection\n",
        "- Keep symbols used in natural language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 text  has_emoji\n",
            "0         Hello world      False\n",
            "1          Hi there üòÄ       True\n",
            "2  @user_name is cool      False\n",
            "3     No emojis here!      False\n",
            "4            symbol ÔøΩ       True\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'text': [\"Hello world\", \"Hi there üòÄ\", \"@user_name is cool\", \"No emojis here!\", \"symbol ÔøΩ\"]\n",
        "})\n",
        "\n",
        "pattern = re.compile(r'[^\\w\\s@.,!?#]', flags=re.UNICODE)\n",
        "df['has_emoji'] = df['text'].apply(lambda x: bool(pattern.search(str(x))))\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test emoji refining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  tweet  \\\n",
            "0     The CDC currently reports 99031 deaths. In gen...   \n",
            "1     States reported 1121 deaths a small rise from ...   \n",
            "2     Politically Correct Woman (Almost) Uses Pandem...   \n",
            "3     #IndiaFightsCorona: We have 1524 #COVID testin...   \n",
            "4     Populous states can generate large case counts...   \n",
            "...                                                 ...   \n",
            "6415  A tiger tested positive for COVID-19 please st...   \n",
            "6416  Autopsies prove that COVID-19 is a blood clot,...   \n",
            "6417  _A post claims a COVID-19 vaccine has already ...   \n",
            "6418  Aamir Khan Donate 250 Cr. In PM Relief Cares Fund   \n",
            "6419  It has been 93 days since the last case of COV...   \n",
            "\n",
            "                                             clean_text  \n",
            "0     The CDC currently reports 99031 deaths. In gen...  \n",
            "1     States reported 1121 deaths a small rise from ...  \n",
            "2     Politically Correct Woman Almost Uses Pandemic...  \n",
            "3     #IndiaFightsCorona We have 1524 #COVID testing...  \n",
            "4     Populous states can generate large case counts...  \n",
            "...                                                 ...  \n",
            "6415  A tiger tested positive for COVID19 please sta...  \n",
            "6416  Autopsies prove that COVID19 is a blood clot, ...  \n",
            "6417  A post claims a COVID19 vaccine has already be...  \n",
            "6418  Aamir Khan Donate 250 Cr. In PM Relief Cares Fund  \n",
            "6419  It has been 93 days since the last case of COV...  \n",
            "\n",
            "[6420 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.DataFrame(train_df)\n",
        "\n",
        "# Step 1: Clean text safely\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    \n",
        "    # Step 1a: Protect @usernames and #hashtags\n",
        "    placeholders = {}\n",
        "    for match in re.findall(r'(@\\w+|#\\w+)', text):\n",
        "        ph = f\"PLACEHOLDER{len(placeholders)}\"\n",
        "        placeholders[ph] = match\n",
        "        text = text.replace(match, ph)\n",
        "    \n",
        "    # Step 1b: Replace all underscores with spaces\n",
        "    text = text.replace('_', ' ')\n",
        "    \n",
        "    # Step 1c: Remove emojis / unusual symbols\n",
        "    # Keep letters, numbers, whitespace, @, #, ., ,, !, ?\n",
        "    text = re.sub(r'[^\\w\\s@.,!?#]', '', text, flags=re.UNICODE)\n",
        "    \n",
        "    # Step 1d: Remove leading punctuation (like . , ! ?) at start of text\n",
        "    text = re.sub(r'^[.,!?_\\s]+', '', text)\n",
        "    \n",
        "    # Step 1e: Restore usernames and hashtags\n",
        "    for ph, original in placeholders.items():\n",
        "        text = text.replace(ph, original)\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Apply cleaning function to the 'tweet' column\n",
        "df['clean_text'] = df['tweet'].apply(clean_text)\n",
        "\n",
        "# Optional: preview result\n",
        "print(df[['tweet', 'clean_text']])\n",
        "\n",
        "# Save cleaned file\n",
        "df.to_excel(\"Constraint_English_Train_Cleaned.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clean emojis on all 3 datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Normalized usernames and hashtags instead of keeping them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned dataset saved to Constraint_English_Train_Cleaned.xlsx\n",
            "Cleaned dataset saved to Constraint_English_Val_Cleaned.xlsx\n",
            "Cleaned dataset saved to Constraint_English_Test_Cleaned.xlsx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/ctip/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
            "/opt/anaconda3/envs/ctip/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Step 1: Define cleaning function\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    \n",
        "    # Step 1a: Normalize links, usernames and hashtags \n",
        "    # Normalize @usernames to <USER>\n",
        "    text = re.sub(r'@\\w+', '<USER>', text)\n",
        "\n",
        "    # Normalize #hashtags to <HASHTAG:topic>\n",
        "    def replace_hashtag(match):\n",
        "        hashtag = match.group()[1:]  # remove #\n",
        "        return f\"<HASHTAG:{hashtag}>\"\n",
        "    \n",
        "    text = re.sub(r'#\\w+', replace_hashtag, text)\n",
        "    \n",
        "    # Normalize links\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '<LINK>', text)\n",
        "    \n",
        "    # Step 1b: Replace all underscores \n",
        "    text = text.replace('_', '')\n",
        "    \n",
        "    # Step 1c: Remove emojis / unusual symbols\n",
        "    # Keep letters, numbers, whitespace, @, #, ., ,, !, ?\n",
        "    text = re.sub(r'[^\\w\\s@.,!?#<>:;]', '', text, flags=re.UNICODE)\n",
        "    \n",
        "    # Step 1d: Remove leading punctuation (like . , ! ?) at start of text\n",
        "    text = re.sub(r'^[.,!?_\\s]+', '', text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "\n",
        "# Step 2: Define helper function for cleaning datasets\n",
        "def clean_dataset(input_path, output_path, text_column='tweet'):\n",
        "    \"\"\"\n",
        "    Reads a dataset, cleans the specified text column, and saves cleaned dataset.\n",
        "    \"\"\"\n",
        "    df = pd.read_excel(input_path)\n",
        "\n",
        "    if text_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{text_column}' not found in dataset.\")\n",
        "\n",
        "    df['clean_text'] = df[text_column].apply(clean_text)\n",
        "\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"Cleaned dataset saved to {output_path}\")\n",
        "\n",
        "\n",
        "# Step 3: Clean train, validation, and test datasets\n",
        "datasets = [\n",
        "    (\"Constraint_English_Train_GR.xlsx\", \"Constraint_English_Train_Cleaned.xlsx\"),\n",
        "    (\"Constraint_English_Val_GR.xlsx\", \"Constraint_English_Val_Cleaned.xlsx\"),\n",
        "    (\"Constraint_English_Test_GR.xlsx\", \"Constraint_English_Test_Cleaned.xlsx\")\n",
        "]\n",
        "\n",
        "for input_path, output_path in datasets:\n",
        "    clean_dataset(input_path, output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Remove Stopwords\n",
        "- use nltk library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/zara/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.6 Lemmatization\n",
        "- Lemmatization cleans word forms that has \"-ing\" so that words are in keyword forms.\n",
        "- uses Spacy or NLTK\n",
        "- choice: Spacy (more accurate and faster, but larger)\n",
        "- it also tokenize words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_ for token in doc if token.lemma_ != \"-PRON-\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 Spelling Correction\n",
        "- Tools available: TextBlob, SymSpell, Hunspell or pyspellchecker\n",
        "- TextBlob - 36.4s (good for small datasets)\n",
        "- Spellchecker - 36.6s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def correct_spelling(text):\n",
        "    return str(TextBlob(text).correct())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/zara/miniconda3/envs/ctip/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt', download_dir=\"/Users/zara/nltk_data\")\n",
        "nltk.data.path.append(\"/Users/zara/miniconda3/envs/ctip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- conda info --envs\n",
        "- replace /Users..... to your own path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4 Improved final code\n",
        "- added hashtag, link and user mention normalization, word lemetization (+ removed spaces due to lemetization), and spell checking.\n",
        "\n",
        "Tools:\n",
        "1. pandas - reading and writing excel datasets (pd.red_excel, df.to_excel)\n",
        "2. re (regex) - Text normalization (usernames, hashtags, links) and symbol removal.\n",
        "3. nltk - stopword removal \n",
        "4. spacy - lemmatization \n",
        "5. textblob - spelling correction\n",
        "6. lambda + regex - placeholder integrity\n",
        "\n",
        "\n",
        "Preprocessing steps taken:\n",
        "- username to <USER>\n",
        "- hashatags to <HASHTAG:topic>\n",
        "- links to <LINK>\n",
        "- removed underscores\n",
        "- removed emojis/weird symbols \n",
        "- removed leading punctuations\n",
        "- removed stopwords - split text intp tokens, filter stopwords and rejoin\n",
        "- lemmatization - convert words to their root form (avoid pronouns)\n",
        "- remove spaces in placeholders after lemmetization\n",
        "- spelling correction \n",
        "\n",
        "Dataset Processing\n",
        "- Reads each dataset (pd.read_excel)\n",
        "- Applies cleaning to a specified column (tweet)\n",
        "- Writes cleaned data to a new Excel file.\n",
        "- Processes multiple datasets in a loop.\n",
        "\n",
        "\n",
        "Observations: there are still some spaces in placeholders <> after lemmetization even when spaces are removed with regex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/zara/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/opt/anaconda3/envs/ctip/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned dataset saved to Constraint_English_Train_Cleaned.xlsx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/ctip/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned dataset saved to Constraint_English_Val_Cleaned.xlsx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/ctip/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned dataset saved to Constraint_English_Test_Cleaned.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "#from spellchecker import SpellChecker\n",
        "\n",
        "#spell = SpellChecker()\n",
        "\n",
        "# Function - Lemmatize\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_ for token in doc if token.lemma_ != \"-PRON-\"])\n",
        "\n",
        "# Function - Remove spaces from lemmaitization\n",
        "def remove_spaces_in_placeholders(text):\n",
        "    return re.sub(r'<\\s*(.*?)\\s*>', lambda m: f\"<{m.group(1).replace(' ', '')}>\", text)\n",
        "\n",
        "# Function - Spelling correction (TextBlob)\n",
        "def correct_spelling(text):\n",
        "    return str(TextBlob(text).correct())\n",
        "\n",
        "# Function - Spelling correction (spellchecker)\n",
        "# def correct_spelling(text):\n",
        "#     return \" \".join(spell.correction(word) or word for word in text.split())\n",
        "\n",
        "# Function - Hashtag normalization function\n",
        "def replace_hashtag(match):\n",
        "    hashtag = match.group()[1:].lower()\n",
        "    return f\"<HASHTAG:{hashtag}>\"\n",
        "\n",
        "# Download stopwords once\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "negations = {\"no\", \"not\", \"nor\", \"never\"}\n",
        "stop_words -= negations\n",
        "\n",
        "# Cleaning function\n",
        "def clean_text(text, do_lemmatize=True, do_spellcheck=False):\n",
        "    text = str(text)\n",
        "\n",
        "    # Normalize usernames, hashtags, and links\n",
        "    text = re.sub(r'@\\w+', '<USER>', text)\n",
        "    text = re.sub(r'#\\w+', replace_hashtag, text)\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '<LINK>', text)\n",
        "\n",
        "    # Remove underscores\n",
        "    text = text.replace('_', '')\n",
        "\n",
        "    # Remove emojis/unusual symbols but keep punctuation\n",
        "    text = re.sub(r'[^\\w\\s@.,!?#<>:;]', '', text, flags=re.UNICODE)\n",
        "\n",
        "    # Remove leading punctuation\n",
        "    text = re.sub(r'^[.,!?_\\s]+', '', text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    text = \" \".join(tokens)\n",
        "\n",
        "    # Lemmatize and remove spaces \n",
        "    if do_lemmatize:\n",
        "        text = lemmatize_text(text)\n",
        "    text = remove_spaces_in_placeholders(text)\n",
        "\n",
        "    # Spellcheck\n",
        "    if do_spellcheck:\n",
        "        text = correct_spelling(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Dataset cleaning helper\n",
        "def clean_dataset(input_path, output_path, text_column='tweet', do_lemmatize=True, do_spellcheck=False):\n",
        "    df = pd.read_excel(input_path)\n",
        "\n",
        "    if text_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{text_column}' not found in dataset.\")\n",
        "\n",
        "    df['clean_text'] = df[text_column].apply(lambda x: clean_text(x, do_lemmatize, do_spellcheck))\n",
        "\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"Cleaned dataset saved to {output_path}\")\n",
        "\n",
        "# Run cleaning for datasets\n",
        "datasets = [\n",
        "    (\"Constraint_English_Train_GR.xlsx\", \"Constraint_English_Train_Cleaned.xlsx\"),\n",
        "    (\"Constraint_English_Val_GR.xlsx\", \"Constraint_English_Val_Cleaned.xlsx\"),\n",
        "    (\"Constraint_English_Test_GR.xlsx\", \"Constraint_English_Test_Cleaned.xlsx\")\n",
        "]\n",
        "\n",
        "for input_path, output_path in datasets:\n",
        "    clean_dataset(input_path, output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.0 Machine Model Selection\n",
        "- supervised ML (classifies real vs fake)\n",
        "- feature extraction: Uses TF-IDF vectorization with:\n",
        "  - Unigrams + bigrams \n",
        "  - vocabulary size limited to 5000 features\n",
        "  - Frequency thresholds:\n",
        "\t- \tmin_df=5 (ignore rare words).\n",
        "\t- \tmax_df=0.9 (remove overly common words).\n",
        "- model selection: \n",
        "  - Logic regression as primary classifier\n",
        "    - Uses max_iter=1000 for convergence stability\n",
        "  - KNN used for baseline comparison\n",
        "    - less effective on sparse data\n",
        "- Evaluation\n",
        "  - metrics report:\n",
        "    - accuracy\n",
        "    - f1 score\n",
        "    - Classification report (precision, recall, F1 per class)\n",
        "    - Confusion matrix heatmap for error analysis.\n",
        "  - Confusion matrix shows counts of correct and incorrect predictions for samples in test dataset. \n",
        "\n",
        "## Why this selection?\n",
        "- TF-IDF + Logistic Regression is a well-established baseline for text classification and misinformation detection, balancing interpretability and performance.\n",
        "- N-grams capture short contextual dependencies that are crucial in misinformation (e.g., ‚Äúnot true‚Äù, ‚Äúfake news‚Äù).\n",
        "- Feature limits & frequency cutoffs prevent overfitting on noise, slang, or rare hashtags.\n",
        "- The inclusion of KNN shows experimentation with alternative models, but Logistic Regression is the practical choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.92      1020\n",
            "           1       0.93      0.94      0.93      1120\n",
            "\n",
            "    accuracy                           0.93      2140\n",
            "   macro avg       0.93      0.93      0.93      2140\n",
            "weighted avg       0.93      0.93      0.93      2140\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.77      0.80        13\n",
            "           1       0.92      0.95      0.94        38\n",
            "\n",
            "    accuracy                           0.90        51\n",
            "   macro avg       0.88      0.86      0.87        51\n",
            "weighted avg       0.90      0.90      0.90        51\n",
            "\n",
            "KNN Validation Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89      1020\n",
            "           1       0.95      0.82      0.88      1120\n",
            "\n",
            "    accuracy                           0.88      2140\n",
            "   macro avg       0.89      0.89      0.88      2140\n",
            "weighted avg       0.89      0.88      0.88      2140\n",
            "\n",
            "KNN Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.85      0.69        13\n",
            "           1       0.94      0.79      0.86        38\n",
            "\n",
            "    accuracy                           0.80        51\n",
            "   macro avg       0.76      0.82      0.77        51\n",
            "weighted avg       0.85      0.80      0.81        51\n",
            "\n",
            "y_test length: 51\n",
            "X_test_vec shape: (51, 4668)\n",
            "Predictions length: 51\n",
            "First few y_test values: 0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: label, dtype: int64\n",
            "First few predictions: [0 1 1 1 1 0 1 1 1 1]\n",
            "Logistic Regression Test Accuracy: 0.9019607843137255\n",
            "Logistic Regression Test F1 Score: 0.935064935064935\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "# Load prcoessed datasets\n",
        "train_df = pd.read_excel(\"Constraint_English_Train_Cleaned.xlsx\")\n",
        "val_df = pd.read_excel(\"Constraint_English_Val_Cleaned.xlsx\")\n",
        "test_df = pd.read_excel(\"Constraint_English_Test_Cleaned.xlsx\")\n",
        "\n",
        "# Labels\n",
        "y_train = train_df['label'].map({'real': 1, 'fake': 0})\n",
        "y_val = val_df['label'].map({'real': 1, 'fake': 0})\n",
        "y_test = test_df['label'].map({'real': 1, 'fake': 0})\n",
        "\n",
        "# TF-IDF vectorization with improvements\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),      # Include unigrams and bigrams\n",
        "    max_features=5000,       # Limit vocabulary size\n",
        "    min_df=5,                # Minimum document frequency\n",
        "    max_df=0.9,              # Remove very common words\n",
        ")\n",
        "\n",
        "# Fit vectorizer on training data\n",
        "X_train_vec = vectorizer.fit_transform(train_df['clean_text'])\n",
        "X_val_vec = vectorizer.transform(val_df['clean_text'])\n",
        "X_test_vec = vectorizer.transform(test_df['clean_text'])\n",
        "\n",
        "# Train Logistic Regression \n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg.fit(X_train_vec, y_train)\n",
        "\n",
        "# Validate model \n",
        "y_val_pred = log_reg.predict(X_val_vec)\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# Test model \n",
        "y_test_pred = log_reg.predict(X_test_vec)\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# # Comparison: KNN \n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_vec, y_train)\n",
        "\n",
        "y_val_pred_knn = knn.predict(X_val_vec)\n",
        "print(\"KNN Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred_knn))\n",
        "\n",
        "y_test_pred_knn = knn.predict(X_test_vec)\n",
        "print(\"KNN Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred_knn))\n",
        "\n",
        "# Test data\n",
        "print(\"y_test length:\", len(y_test))\n",
        "print(\"X_test_vec shape:\", X_test_vec.shape)\n",
        "print(\"Predictions length:\", len(y_test_pred))\n",
        "print(\"First few y_test values:\", y_test.head())\n",
        "print(\"First few predictions:\", y_test_pred[:10])\n",
        "print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Logistic Regression Test F1 Score:\", f1_score(y_test, y_test_pred))\n",
        "\n",
        "# Metrics and Confusion Matrix \n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "y-axis:\n",
        "0 Actual Negative\n",
        "1 Actual Postive\n",
        "\n",
        "x-axis:\n",
        "0 Predicted Negative\n",
        "1 Predicated positive\n",
        "\n",
        "0,0 - True Negative\n",
        "0,1 - False Negative\n",
        "0,1 - False Positve\n",
        "1,1 - True Postive\n",
        "\n",
        "- 10 Samples were actually fake, and correctly predicted as fake\n",
        "- 36 Samples were acutally true, and correctly predicted as true "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extras: Tests and Comparisons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of bigrams: 2042\n",
            "Example bigrams: ['00 confirmed', '00 pm', '000 people', '04 2020', '08 00', '09 30', '10 000', '10 day', '10 lakh', '10 million', '10 pm', '10 second', '10 statesuts', '100 people', '1000 death', '1000 link', '10000 case', '1000190000 confirm', '11 00', '11 lakh']\n"
          ]
        }
      ],
      "source": [
        "# Get all features (unigrams + bigrams)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Filter only bigrams (words with a space)\n",
        "bigrams = [word for word in feature_names if \" \" in word]\n",
        "\n",
        "print(f\"Number of bigrams: {len(bigrams)}\")\n",
        "print(\"Example bigrams:\", bigrams[:20])\n",
        "\n",
        "bigram_vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(2, 2),   # Only bigrams\n",
        "    max_features=5000,\n",
        "    min_df=5,\n",
        "    max_df=0.9\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vectorizer that only uses bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results (Bigrams Only):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.89      1020\n",
            "           1       0.91      0.88      0.90      1120\n",
            "\n",
            "    accuracy                           0.89      2140\n",
            "   macro avg       0.89      0.89      0.89      2140\n",
            "weighted avg       0.89      0.89      0.89      2140\n",
            "\n",
            "Test Results (Bigrams Only):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.92      0.80        13\n",
            "           1       0.97      0.87      0.92        38\n",
            "\n",
            "    accuracy                           0.88        51\n",
            "   macro avg       0.84      0.90      0.86        51\n",
            "weighted avg       0.90      0.88      0.89        51\n",
            "\n",
            "Bigram Test Accuracy: 0.8823529411764706\n",
            "Bigram Test F1 Score: 0.9166666666666666\n"
          ]
        }
      ],
      "source": [
        "bigram_vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(2, 2),   # Only bigrams\n",
        "    max_features=5000,\n",
        "    min_df=5,\n",
        "    max_df=0.9\n",
        ")\n",
        "\n",
        "X_train_bigram = bigram_vectorizer.fit_transform(train_df['clean_text'])\n",
        "X_val_bigram = bigram_vectorizer.transform(val_df['clean_text'])\n",
        "X_test_bigram = bigram_vectorizer.transform(test_df['clean_text'])\n",
        "\n",
        "log_reg_bigram = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg_bigram.fit(X_train_bigram, y_train)\n",
        "\n",
        "y_val_pred_bigram = log_reg_bigram.predict(X_val_bigram)\n",
        "y_test_pred_bigram = log_reg_bigram.predict(X_test_bigram)\n",
        "\n",
        "print(\"Validation Results (Bigrams Only):\")\n",
        "print(classification_report(y_val, y_val_pred_bigram))\n",
        "\n",
        "print(\"Test Results (Bigrams Only):\")\n",
        "print(classification_report(y_test, y_test_pred_bigram))\n",
        "\n",
        "print(\"Bigram Test Accuracy:\", accuracy_score(y_test, y_test_pred_bigram))\n",
        "print(\"Bigram Test F1 Score:\", f1_score(y_test, y_test_pred_bigram))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Most influential bigrams\n",
        "- uses logistic regression coeffiecients mapped back to features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top influential bigrams:\n",
            "                        feature      coef\n",
            "1860            hashtag covid19  7.360339\n",
            "2432               link hashtag -3.221148\n",
            "953         coronavirus hashtag -3.172796\n",
            "3604                    rt user  2.639841\n",
            "1885  hashtag indiafightscorona  2.365095\n",
            "4408               user hashtag  2.026406\n",
            "1061            covid19 hashtag -1.881090\n",
            "652                case hashtag  1.746163\n",
            "1852    hashtag coronavirusfact -1.683887\n",
            "1964                  here link  1.639278\n",
            "1859              hashtag covid  1.576866\n",
            "2733            new coronavirus -1.513123\n",
            "1020                   covid 19 -1.357053\n",
            "2663                  more link  1.327422\n",
            "3892               state report  1.288036\n",
            "943            coronavirus case -1.281925\n",
            "3858             spread hashtag  1.271841\n",
            "974        coronavirusfact link -1.252866\n",
            "4244               total number  1.246529\n",
            "2513           manage isolation  1.244630\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "coef = log_reg.coef_[0]\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create dataframe\n",
        "coef_df = pd.DataFrame({\n",
        "    \"feature\": feature_names,\n",
        "    \"coef\": coef\n",
        "})\n",
        "\n",
        "# Filter bigrams\n",
        "bigram_coef_df = coef_df[coef_df['feature'].str.contains(\" \")]\n",
        "\n",
        "# Sort by absolute coefficient value\n",
        "bigram_coef_df = bigram_coef_df.reindex(bigram_coef_df.coef.abs().sort_values(ascending=False).index)\n",
        "\n",
        "print(\"Top influential bigrams:\")\n",
        "print(bigram_coef_df.head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Testing ngram_range=(1, 1) ===\n",
            "Validation Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.91      1020\n",
            "           1       0.91      0.92      0.92      1120\n",
            "\n",
            "    accuracy                           0.91      2140\n",
            "   macro avg       0.91      0.91      0.91      2140\n",
            "weighted avg       0.91      0.91      0.91      2140\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.77      0.80        13\n",
            "           1       0.92      0.95      0.94        38\n",
            "\n",
            "    accuracy                           0.90        51\n",
            "   macro avg       0.88      0.86      0.87        51\n",
            "weighted avg       0.90      0.90      0.90        51\n",
            "\n",
            "\n",
            "=== Testing ngram_range=(2, 2) ===\n",
            "Validation Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.89      1020\n",
            "           1       0.91      0.88      0.90      1120\n",
            "\n",
            "    accuracy                           0.89      2140\n",
            "   macro avg       0.89      0.89      0.89      2140\n",
            "weighted avg       0.89      0.89      0.89      2140\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.92      0.80        13\n",
            "           1       0.97      0.87      0.92        38\n",
            "\n",
            "    accuracy                           0.88        51\n",
            "   macro avg       0.84      0.90      0.86        51\n",
            "weighted avg       0.90      0.88      0.89        51\n",
            "\n",
            "\n",
            "Top 20 bigrams for ngram_range=(2, 2):\n",
            "hashtag covid19: 6.5068\n",
            "hashtag indiafightscorona: 4.3761\n",
            "coronavirus hashtag: -4.0151\n",
            "state report: 3.8964\n",
            "rt user: 3.1540\n",
            "total number: 3.1000\n",
            "user hashtag: 2.9227\n",
            "here link: 2.8996\n",
            "manage isolation: 2.7391\n",
            "covid19 hashtag: -2.7229\n",
            "new case: 2.5798\n",
            "active case: 2.4952\n",
            "donald trump: -2.4902\n",
            "7day average: 2.3185\n",
            "case hashtag: 2.3132\n",
            "hashtag covid: 2.2845\n",
            "people test: 2.2604\n",
            "novel coronavirus: -2.2317\n",
            "cure covid19: -2.2090\n",
            "new coronavirus: -2.1387\n",
            "\n",
            "=== Testing ngram_range=(1, 2) ===\n",
            "Validation Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.92      1020\n",
            "           1       0.93      0.94      0.93      1120\n",
            "\n",
            "    accuracy                           0.93      2140\n",
            "   macro avg       0.93      0.93      0.93      2140\n",
            "weighted avg       0.93      0.93      0.93      2140\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.77      0.80        13\n",
            "           1       0.92      0.95      0.94        38\n",
            "\n",
            "    accuracy                           0.90        51\n",
            "   macro avg       0.88      0.86      0.87        51\n",
            "weighted avg       0.90      0.90      0.90        51\n",
            "\n",
            "\n",
            "Top 20 bigrams for ngram_range=(1, 2):\n",
            "hashtag covid19: 7.3603\n",
            "link hashtag: -3.2211\n",
            "coronavirus hashtag: -3.1728\n",
            "rt user: 2.6398\n",
            "hashtag indiafightscorona: 2.3651\n",
            "user hashtag: 2.0264\n",
            "covid19 hashtag: -1.8811\n",
            "case hashtag: 1.7462\n",
            "hashtag coronavirusfact: -1.6839\n",
            "here link: 1.6393\n",
            "hashtag covid: 1.5769\n",
            "new coronavirus: -1.5131\n",
            "covid 19: -1.3571\n",
            "more link: 1.3274\n",
            "state report: 1.2880\n",
            "coronavirus case: -1.2819\n",
            "spread hashtag: 1.2718\n",
            "coronavirusfact link: -1.2529\n",
            "total number: 1.2465\n",
            "manage isolation: 1.2446\n",
            "\n",
            "=== Ngram Range Performance Comparison ===\n",
            "  ngram_range  val_accuracy    val_f1  test_accuracy   test_f1\n",
            "0      (1, 1)      0.913084  0.917260       0.901961  0.935065\n",
            "1      (2, 2)      0.892056  0.895143       0.882353  0.916667\n",
            "2      (1, 2)      0.927570  0.931264       0.901961  0.935065\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def test_ngram_ranges_with_bigrams(train_texts, val_texts, test_texts, y_train, y_val, y_test,\n",
        "                                     max_features=5000, min_df=5, max_df=0.9,\n",
        "                                     top_n_bigrams=20):\n",
        "    results = []\n",
        "\n",
        "    for ngram_range in [(1, 1), (2, 2), (1, 2)]:\n",
        "        print(f\"\\n=== Testing ngram_range={ngram_range} ===\")\n",
        "\n",
        "        vectorizer = TfidfVectorizer(\n",
        "            ngram_range=ngram_range,\n",
        "            max_features=max_features,\n",
        "            min_df=min_df,\n",
        "            max_df=max_df\n",
        "        )\n",
        "\n",
        "        X_train_vec = vectorizer.fit_transform(train_texts)\n",
        "        X_val_vec = vectorizer.transform(val_texts)\n",
        "        X_test_vec = vectorizer.transform(test_texts)\n",
        "\n",
        "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "        model.fit(X_train_vec, y_train)\n",
        "\n",
        "        y_val_pred = model.predict(X_val_vec)\n",
        "        y_test_pred = model.predict(X_test_vec)\n",
        "\n",
        "        val_acc = accuracy_score(y_val, y_val_pred)\n",
        "        val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "        test_acc = accuracy_score(y_test, y_test_pred)\n",
        "        test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "        print(\"Validation Results:\")\n",
        "        print(classification_report(y_val, y_val_pred))\n",
        "        print(\"Test Results:\")\n",
        "        print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "        results.append({\n",
        "            \"ngram_range\": ngram_range,\n",
        "            \"val_accuracy\": val_acc,\n",
        "            \"val_f1\": val_f1,\n",
        "            \"test_accuracy\": test_acc,\n",
        "            \"test_f1\": test_f1\n",
        "        })\n",
        "\n",
        "        # If bigrams are included, show top bigrams\n",
        "        if ngram_range[1] >= 2:\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "            coef = model.coef_[0]\n",
        "\n",
        "            bigram_features = [\n",
        "                (feature, coef[i])\n",
        "                for i, feature in enumerate(feature_names) if \" \" in feature\n",
        "            ]\n",
        "\n",
        "            bigram_features_sorted = sorted(bigram_features, key=lambda x: abs(x[1]), reverse=True)\n",
        "            print(f\"\\nTop {top_n_bigrams} bigrams for ngram_range={ngram_range}:\")\n",
        "            for feature, weight in bigram_features_sorted[:top_n_bigrams]:\n",
        "                print(f\"{feature}: {weight:.4f}\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Usage:\n",
        "comparison_df = test_ngram_ranges_with_bigrams(\n",
        "    train_df['clean_text'],\n",
        "    val_df['clean_text'],\n",
        "    test_df['clean_text'],\n",
        "    y_train, y_val, y_test\n",
        ")\n",
        "\n",
        "print(\"\\n=== Ngram Range Performance Comparison ===\")\n",
        "print(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes:\n",
        "- (1,1) Unigrams\n",
        "- (2,2) Bigrams\n",
        "- (1,2) Unigrams + Bigrams"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ctip",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
